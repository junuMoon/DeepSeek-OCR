time="2025-11-17T20:45:06+09:00" level=warning msg="/home/fran/DeepSeek-OCR/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion"
INFO 11-17 11:45:09 [__init__.py:239] Automatically detected platform cuda.
INFO 11-17 11:45:12 [config.py:456] Overriding HF config with {'architectures': ['DeepseekOCRForCausalLM']}
INFO 11-17 11:45:12 [config.py:717] This model supports multiple tasks: {'classify', 'reward', 'generate', 'embed', 'score'}. Defaulting to 'generate'.
INFO 11-17 11:45:12 [llm_engine.py:240] Initializing a V0 LLM engine (v0.8.5) with config: model='/models/deepseek-ai/DeepSeek-OCR', speculative_config=None, tokenizer='/models/deepseek-ai/DeepSeek-OCR', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=/models/deepseek-ai/DeepSeek-OCR, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":[],"compile_sizes":[],"cudagraph_capture_sizes":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":256}, use_cached_outputs=False, 
INFO 11-17 11:45:13 [cuda.py:292] Using Flash Attention backend.
INFO 11-17 11:45:14 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 11-17 11:45:14 [model_runner.py:1108] Starting to load model /models/deepseek-ai/DeepSeek-OCR...
INFO 11-17 11:45:15 [config.py:3614] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256] is overridden by config [256, 128, 2, 1, 4, 136, 8, 144, 16, 152, 24, 160, 32, 168, 40, 176, 48, 184, 56, 192, 64, 200, 72, 208, 80, 216, 88, 120, 224, 96, 232, 104, 240, 112, 248]
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 11.08it/s]

INFO 11-17 11:45:17 [loader.py:458] Loading weights took 2.29 seconds
INFO 11-17 11:45:18 [model_runner.py:1140] Model loading took 6.2319 GiB and 3.328175 seconds
Some kwargs in processor config are unused and will not have any effect: mask_prompt, patch_size, sft_format, image_std, image_token, normalize, pad_token, candidate_resolutions, ignore_id, image_mean, add_special_token, downsample_ratio. 
WARNING 11-17 11:45:22 [fused_moe.py:668] Using default MoE config. Performance might be sub-optimal! Config file not found at /usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/fused_moe/configs/E=64,N=896,device_name=NVIDIA_A100-SXM4-80GB.json
INFO 11-17 11:45:24 [worker.py:287] Memory profiling takes 6.39 seconds
INFO 11-17 11:45:24 [worker.py:287] the current vLLM instance can use total_gpu_memory (79.14GiB) x gpu_memory_utilization (0.50) = 39.57GiB
INFO 11-17 11:45:24 [worker.py:287] model weights take 6.23GiB; non_torch_memory takes -0.20GiB; PyTorch activation peak memory takes 0.86GiB; the rest of the memory reserved for KV Cache is 32.67GiB.
INFO 11-17 11:45:25 [executor_base.py:112] # cuda blocks: 2230, # CPU blocks: 273
INFO 11-17 11:45:25 [executor_base.py:117] Maximum concurrency for 8192 tokens per request: 69.69x
INFO 11-17 11:45:29 [model_runner.py:1450] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
Capturing CUDA graph shapes:   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graph shapes:   3%|▎         | 1/35 [00:00<00:19,  1.77it/s]Capturing CUDA graph shapes:   6%|▌         | 2/35 [00:00<00:15,  2.19it/s]Capturing CUDA graph shapes:   9%|▊         | 3/35 [00:01<00:13,  2.36it/s]Capturing CUDA graph shapes:  11%|█▏        | 4/35 [00:01<00:12,  2.43it/s]Capturing CUDA graph shapes:  14%|█▍        | 5/35 [00:02<00:12,  2.36it/s]Capturing CUDA graph shapes:  17%|█▋        | 6/35 [00:02<00:11,  2.42it/s]Capturing CUDA graph shapes:  20%|██        | 7/35 [00:02<00:11,  2.49it/s]Capturing CUDA graph shapes:  23%|██▎       | 8/35 [00:03<00:10,  2.54it/s]Capturing CUDA graph shapes:  26%|██▌       | 9/35 [00:03<00:10,  2.52it/s]Capturing CUDA graph shapes:  29%|██▊       | 10/35 [00:04<00:09,  2.58it/s]Capturing CUDA graph shapes:  31%|███▏      | 11/35 [00:04<00:10,  2.22it/s]Capturing CUDA graph shapes:  34%|███▍      | 12/35 [00:05<00:11,  1.93it/s]Capturing CUDA graph shapes:  37%|███▋      | 13/35 [00:05<00:10,  2.02it/s]Capturing CUDA graph shapes:  40%|████      | 14/35 [00:06<00:09,  2.16it/s]Capturing CUDA graph shapes:  43%|████▎     | 15/35 [00:06<00:08,  2.29it/s]Capturing CUDA graph shapes:  46%|████▌     | 16/35 [00:06<00:07,  2.39it/s]Capturing CUDA graph shapes:  49%|████▊     | 17/35 [00:07<00:07,  2.47it/s]Capturing CUDA graph shapes:  51%|█████▏    | 18/35 [00:07<00:06,  2.46it/s]Capturing CUDA graph shapes:  54%|█████▍    | 19/35 [00:08<00:06,  2.44it/s]Capturing CUDA graph shapes:  57%|█████▋    | 20/35 [00:08<00:06,  2.50it/s]Capturing CUDA graph shapes:  60%|██████    | 21/35 [00:08<00:05,  2.51it/s]Capturing CUDA graph shapes:  63%|██████▎   | 22/35 [00:09<00:05,  2.56it/s]Capturing CUDA graph shapes:  66%|██████▌   | 23/35 [00:09<00:04,  2.55it/s]Capturing CUDA graph shapes:  69%|██████▊   | 24/35 [00:10<00:04,  2.55it/s]Capturing CUDA graph shapes:  71%|███████▏  | 25/35 [00:11<00:06,  1.63it/s]Capturing CUDA graph shapes:  74%|███████▍  | 26/35 [00:11<00:04,  1.85it/s]Capturing CUDA graph shapes:  77%|███████▋  | 27/35 [00:11<00:03,  2.00it/s]Capturing CUDA graph shapes:  80%|████████  | 28/35 [00:12<00:03,  2.12it/s]Capturing CUDA graph shapes:  83%|████████▎ | 29/35 [00:12<00:02,  2.21it/s]Capturing CUDA graph shapes:  86%|████████▌ | 30/35 [00:13<00:02,  2.33it/s]Capturing CUDA graph shapes:  89%|████████▊ | 31/35 [00:13<00:01,  2.40it/s]Capturing CUDA graph shapes:  91%|█████████▏| 32/35 [00:13<00:01,  2.47it/s]Capturing CUDA graph shapes:  94%|█████████▍| 33/35 [00:14<00:01,  1.76it/s]Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [00:15<00:00,  1.65it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:15<00:00,  1.86it/s]Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:15<00:00,  2.19it/s]
INFO 11-17 11:45:45 [model_runner.py:1592] Graph capturing finished in 16 secs, took 0.35 GiB
INFO 11-17 11:45:45 [llm_engine.py:437] init engine (profile, create kv cache, warmup model) took 27.32 seconds
INFO 11-17 11:45:45 [async_llm_engine.py:211] Added request request-1763379945.
Some kwargs in processor config are unused and will not have any effect: mask_prompt, patch_size, sft_format, image_std, image_token, normalize, pad_token, candidate_resolutions, ignore_id, image_mean, add_special_token, downsample_ratio. 
<|ref|>image<|/ref|><|det|>[[45, 245, 953, 850]]<|/det|>
<|ref|>image_caption<|/ref|><|det|>[[34, 888, 965, 972]]<|/det|>
<center>Figure 1: Demonstration of PPO and GRPO training with the search engine (SEARCH-R1). During the rollout, LLMs can conduct multi-turn interactions with the search engine. </center>INFO 11-17 11:45:48 [async_llm_engine.py:179] Finished request request-1763379945.


INFO 11-17 11:45:48 [async_llm_engine.py:65] Engine is gracefully shutting down.
===============save results:===============
image:   0%|          | 0/1 [00:00<?, ?it/s]image: 100%|██████████| 1/1 [00:00<00:00, 29959.31it/s]
other:   0%|          | 0/1 [00:00<?, ?it/s]other: 100%|██████████| 1/1 [00:00<00:00, 49344.75it/s]
[rank0]:[W1117 11:45:49.872029090 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
