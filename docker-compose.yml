version: '3.8'

services:
  deepseek-ocr:
    build:
      context: .
      dockerfile: Dockerfile
    image: deepseek-ocr:latest
    container_name: deepseek-ocr
    runtime: nvidia
    environment:
      # Don't set CUDA_VISIBLE_DEVICES - Docker handles GPU assignment via device_ids
      - MODEL_PATH=${MODEL_PATH}
      - VLLM_USE_V1=0
      - TRITON_PTXAS_PATH=/usr/local/cuda-11.8/bin/ptxas
    volumes:
      # Mount model directory (read-only)
      - /nfs/train/llm-lab/models:/models:ro
      # Mount DeepSeek-OCR code
      - ./DeepSeek-OCR-master:/app/DeepSeek-OCR-master
      # Mount current directory for development
      - .:/workspace
    ports:
      - "${PORT:-8000}:8000"
    working_dir: /app
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['7']
              capabilities: [gpu]
    # Development mode: interactive bash shell
    # command: /bin/bash
    # Production mode: run FastAPI server
    command: uvicorn api.main:app --host 0.0.0.0 --port 8000 --workers 1
